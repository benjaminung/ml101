{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is binary classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data has two possible values for the output/dependent variable\n",
    "- Every $y$ is:\n",
    "    - $0$ or $1$\n",
    "    - $-1$ or $1$\n",
    "    - yes or no\n",
    "    - true or false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data: admission to Elay University, a fictional selective university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data below contains three columns:\n",
    "    1. acceptance response\n",
    "    1. amount donated to the university from the applicant's family\n",
    "    1. the applicant's high school GPA\n",
    "- The $y$ values for this data is the acceptance response which can be only one of two values:\n",
    "    1. accepted\n",
    "    2. not accepted\n",
    "- Accepted will be $y=1$ and not accepted will be $y=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.subplots as psub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = torch.load('elay_acceptance.pt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x=\"donations\", y=\"gpa\", symbol='response', color='response')\n",
    "fig.update_traces(opacity=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does logistic regression do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find line that separates data best\n",
    "- Above the line is \"accepted\"\n",
    "- below the line is \"not accepted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-One Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss is 0 if you make the correct prediction, 1 otherwise\n",
    "- Above the line will predict $\\hat{y}^{(i)}=1$\n",
    "- Below the line will predict $\\hat{y}^{(i)}=-1$\n",
    "  $$ l^{(i)} = \\begin{cases} \n",
    "      0 & \\text{if} \\ \\ \\hat{y}^{(i)} = y^{(i)} \\\\\n",
    "      1 & \\text{if} \\ \\ \\hat{y}^{(i)} \\neq y^{(i)}\n",
    "   \\end{cases} $$\n",
    "- This is a step function\n",
    "- The gradient of this function is undefined at the separating line and zero everywhere else. Gradient descent can't be used here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instead of making a binary prediction (0 or 1), predict the probability of being accepted.\n",
    "- Probabilities are between 0.0 and 1.0\n",
    "- A standard logistic function (also called a sigmoid) will take any number as an input and return a value between 0.0 and 1.0\n",
    "    $$ f(z) = \\frac{1}{1+e^{-z}} $$\n",
    "- Code to graph this function is below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    return 1/(1+torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs = torch.linspace(-10,10,100)\n",
    "Values = logistic(Zs)\n",
    "px.line(x=Zs, y=Values, title='Logistic function').update_xaxes(title='z').update_yaxes(title='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We can plug distance from the line/boundary as the input to the logistic function where $z$ is:\n",
    "    $$ \\hat{y}^{(i)} = \\frac{1}{1+ \\exp (-z^{(i)})} $$\n",
    "    - in our case:\n",
    "    $$ z^{(i)} = b +  w_1 x_1^{(i)} + w_2 x_2^{(i)} $$\n",
    "    - *keep in mind that when plotting this data $x_2$ is what's displayed on \"y-axis\"/vertical-axis although it is not our output/y-variable.*\n",
    "    - in general with any number of x-variable components:\n",
    "    $$ z^{(i)} = b + \\bm{w} \\cdot \\bm{x}^{(i)} $$\n",
    "- A point on the boundary that separates the data will have probability equal to $0.5$ or $\\hat{y}^{(i)} = 0.5$\n",
    "- A point above the boundary will have $\\hat{y}^{(i)} \\geq 0.5$\n",
    "- A point below the boundary will have $\\hat{y}^{(i)} \\leq 0.5$\n",
    "- We can multiply both sides by any factor and it won't change the position of the boundary that separates the data\n",
    "    - This factor adjusts the steepness of the logistic curve\n",
    "    - A factor greater than one makes it steeper, which means a point one unit above the boundary will now have a higher probability (closer to 1.0) than before\n",
    "    - A factor less than one makes it less steep, which means a point one unit above the boundary will now have a lower probability (closer to 0.5) than before\n",
    "    - A negative factor flips the side that is the positve/true/1 prediction to the other side of the boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that you have an equation to predict a probability for each of our data points, you can see how likely it is to produce our dataset\n",
    "- We're going to assume the acceptance of applicants is independent from each other\n",
    "- Probability of two independent events is the product of their probabilities\n",
    "  $$ P(y^{(i)} | \\hat{y}^{(i)}) = \\begin{cases} \n",
    "      P(y^{(i)} = 1 | \\hat{y}^{(i)}) = \\hat{y}^{(i)}) \\\\\n",
    "      P(y^{(i)} = 0 | \\hat{y}^{(i)}) = 1 - \\hat{y}^{(i)})\n",
    "   \\end{cases} $$\n",
    "  $$\\text{or}$$\n",
    "  $$ P(y^{(i)} | \\hat{y}^{(i)}) = y^{(i)} \\hat{y}^{(i)} + (1-y^{(i)}) (1-\\hat{y}^{(i)})$$\n",
    "  $$ P(\\bm{y} | \\hat{\\bm{y}}) = \\prod_{i=1}^{N} P(y^{(i)} | \\hat{y}^{(i)}) = P(y^{(1)} | \\hat{y}^{(1)}) \\cdot P(y^{(2)} | \\hat{y}^{(2)}) \\cdot ... \\cdot P(y^{(N)} | \\hat{y}^{(N)})$$\n",
    "- We want to take find the $\\bm{w}$ and $b$ that maximize the likelihood:\n",
    "  $$ \\underset{b, \\bm{w}}{\\operatorname{arg\\ max}} \\  P(\\bm{y} | \\hat{\\bm{y}})$$\n",
    "- The calculus for all those products is difficult so..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Taking the log of a function does not affect its $\\arg \\max$ or $\\arg \\min$\n",
    "- If you take the log of the likelihood it makes the calculus easier\n",
    "    - $\\ln (vw) = \\ln(v) + \\ln(w)$\n",
    "- Take the natural log of our likelihood function\n",
    "$$ \\ln P(\\bm{y} | \\hat{\\bm{y}}) = \\ln \\prod_{i=1}^{N} P(y^{(i)} | \\hat{y}^{(i)}) = \\sum_{i=1}^{N} \\ln P(y^{(i)} | \\hat{y}^{(i)}) = \\ln P(y^{(1)} | \\hat{y}^{(1)}) + \\ln P(y^{(2)} | \\hat{y}^{(2)}) + ... + \\ln P(y^{(N)} | \\hat{y}^{(N)})$$\n",
    "$$ \\ln P(y^{(i)} | \\hat{y}^{(i)}) = \\begin{cases} \n",
    "      \\ln \\left( \\hat{y}^{(i)} \\right) & \\text{if} \\ \\ y^{(i)} = 1 \\\\\n",
    "      \\ln \\left( 1 - \\hat{y}^{(i)} \\right) & \\text{if} \\ \\ y^{(i)} = 0\n",
    "   \\end{cases} $$\n",
    "$$\\text{or}$$\n",
    "$$ \\ln P(y^{(i)} | \\hat{y}^{(i)}) = y^{(i)} \\ln \\left( \\hat{y}^{(i)} \\right) + \\left( 1-y^{(i)} \\right) \\ln \\left( 1-\\hat{y}^{(i)} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Log Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to maximize the log-likelihood not minimize it\n",
    "- We would have to do gradient **ascent** on log-likelihood\n",
    "- or we could just multiply the log-likelihood by $-1$ and use the same gradient descent we have been using\n",
    "$$ \\underset{b, \\bm{w}}{\\operatorname{arg\\ min}} \\quad  - \\ln P(\\bm{y} | \\hat{\\bm{y}})$$\n",
    "$$ \\underset{b, \\bm{w}}{\\operatorname{arg\\ min}} \\quad  \\sum_{i=1}^{N} \\left[ - y^{(i)} \\ln \\left( \\hat{y}^{(i)} \\right) - (1-y^{(i)}) \\ln \\left( 1-\\hat{y}^{(i)} \\right) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Negative log-likelihood is the loss function for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    assert isinstance(data, torch.Tensor) # check that data is a pytorch tensor\n",
    "    column_mu = data.mean(dim=0) # take the mean of each column\n",
    "    column_sigma = data.std(dim=0) # take the std deviation of each column\n",
    "    data_standardized = (data-column_mu)/column_sigma # subract each values column mean then divide by the column std deviation\n",
    "    return data_standardized, column_mu, column_sigma\n",
    "\n",
    "def unstandardize(data_stand, column_mu, column_sigma):\n",
    "    assert isinstance(data_stand, torch.Tensor)\n",
    "    return data_stand * column_sigma + column_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, mus, stds = standardize(torch.tensor(df[['donations','gpa']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = torch.tensor(df['response'] == 'accepted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train, validate, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_order_indices = torch.randperm(len(X_all)) # random order of X_all's indices\n",
    "train_proportion = 0.7\n",
    "valid_proportion = 0.15\n",
    "test_proportion = 0.15\n",
    "train_valid_index_border = torch.math.floor(len(X_all)*train_proportion)\n",
    "valid_test_index_border = torch.math.floor(len(X_all)*(train_proportion+valid_proportion))\n",
    "train_indices = random_order_indices[0:train_valid_index_border] # take first 80% of random_order_indices to be the train indices\n",
    "valid_indices = random_order_indices[train_valid_index_border:valid_test_index_border]\n",
    "test_indices = random_order_indices[valid_test_index_border:]\n",
    "\n",
    "X = X_all[train_indices]\n",
    "Y = Y_all[train_indices]\n",
    "X_valid = X_all[valid_indices]\n",
    "Y_valid = Y_all[valid_indices]\n",
    "X_test  = X_all[test_indices]\n",
    "Y_test  = Y_all[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your own pytorch module that will be our logistic regression module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(torch.nn.Module): # inherits from torch.nn.Module\n",
    "    def __init__(self): # defines initialization of this module\n",
    "        super().__init__() # calls the parent class' (torch.nn.Module) initializer\n",
    "        self.linear = torch.nn.Linear(in_features=2, out_features=1) # linear part of logistic regression\n",
    "        self.sigmoid = torch.nn.Sigmoid() # exponential part of logistic regression\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.linear(x) # apply the linear part\n",
    "        y_pred = self.sigmoid(z) # apply the logistic/sigmoid part\n",
    "        return y_pred # return the probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you can use a different metric other than your loss function to measure the performance of your model\n",
    "- sometimes your loss function is difficult to explain to other people\n",
    "- sometimes your loss function doesn't directly measure your goal\n",
    "    - in logistic regression the loss function (negative log-likelihood) doesn't tell you directly how many predictions you got right vs wrong\n",
    "    - zero-one loss would directly measure our goal but it wouldn't work with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogReg() # initialize logist\n",
    "optim = torch.optim.SGD(log_reg.parameters(), lr=1.0)\n",
    "epoch = 0\n",
    "Losses = []\n",
    "Losses_valid = []\n",
    "Accuracy = []\n",
    "Accuracy_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_steps(title):\n",
    "    Losses = []\n",
    "    Losses_valid = []\n",
    "    Acc = []\n",
    "    Acc_valid = []\n",
    "    fig = go.FigureWidget(psub.make_subplots(rows=1, cols=2, subplot_titles=('Loss', 'Accuracy')))\n",
    "    \n",
    "    trace_train = go.Scatter( x=list(range(len(Losses))), y=Losses, line=dict(color=px.colors.qualitative.Plotly[0]), name='train loss' )\n",
    "    fig.add_trace(trace_train, row=1, col=1)\n",
    "    \n",
    "    trace_valid = go.Scatter( x=list(range(len(Losses_valid))), y=Losses_valid, line=dict(color=px.colors.qualitative.Plotly[1]), name='valid loss' )\n",
    "    fig.add_trace(trace_valid, row=1, col=1)\n",
    "    \n",
    "    trace_train_acc = go.Scatter( x=list(range(len(Losses))), y=Losses, line=dict(color=px.colors.qualitative.Plotly[2]), name='train accuracy' )\n",
    "    fig.add_trace(trace_train_acc, row=1, col=2)\n",
    "    \n",
    "    trace_valid_acc = go.Scatter( x=list(range(len(Losses_valid))), y=Losses_valid, line=dict(color=px.colors.qualitative.Plotly[3]), name='valid accuracy' )\n",
    "    fig.add_trace(trace_valid_acc, row=1, col=2)\n",
    "    \n",
    "    fig.update_layout( autosize=False, width=1500, height=500, title=title)\n",
    "    fig.update_xaxes( title=\"steps\", row=1, col=1)\n",
    "    fig.update_yaxes( title='loss', row=1, col=1)\n",
    "    fig.update_xaxes( title=\"steps\", row=1, col=2)\n",
    "    fig.update_yaxes( title='accuracy', row=1, col=2)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(X, Y, X_valid, Y_valid, model, optim, Losses, Losses_valid, Accuracy, Accuracy_valid):\n",
    "    global epoch\n",
    "    print('epoch #{}'.format(epoch))\n",
    "    optim.zero_grad() # reset the gradients\n",
    "    model.train() # tells pytorch we're training the linear module\n",
    "\n",
    "    pred_y = model(X).squeeze() # make a prediction\n",
    "\n",
    "    loss = torch.nn.functional.binary_cross_entropy(pred_y, Y.float()) # calculate logistic loss\n",
    "    loss.backward() # calculate gradients\n",
    "    optim.step() # take gradient descent step\n",
    "    \n",
    "    pred_y_binary = pred_y > 0.5\n",
    "    accuracy = (pred_y_binary == Y).float().mean()\n",
    "\n",
    "    model.eval() # tells pytorch we're not training our linear module (we're validating now instead of training)\n",
    "    with torch.no_grad(): # Tells pytorch to not track gradients. This prevents unnecessary calculations and memory usage\n",
    "        pred_y_valid = model(X_valid).squeeze()\n",
    "        loss_valid = torch.nn.functional.binary_cross_entropy(pred_y_valid, Y_valid.float())\n",
    "        pred_y_valid_binary = pred_y_valid > 0.5\n",
    "        accuracy_valid = (pred_y_valid_binary == Y_valid).float().mean()\n",
    "\n",
    "    Losses.append(loss.item()) # add current training loss to Losses list\n",
    "    Losses_valid.append(loss_valid.item()) # add current validation loss to Losses_valid list\n",
    "    Accuracy.append(accuracy.item())\n",
    "    Accuracy_valid.append(accuracy_valid.item())\n",
    "    print('Validation Loss: ' + str(loss_valid.item()))\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = graph_steps('Logistic Loss')\n",
    "train_loss = fig.data[0] # use this variable to add train losses to graph\n",
    "valid_loss = fig.data[1] # use this variable to add validation losses to graph\n",
    "train_acc = fig.data[2]\n",
    "valid_acc = fig.data[3]\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step(X, Y, X_valid, Y_valid, log_reg, optim, Losses, Losses_valid, Accuracy, Accuracy_valid)\n",
    "# if Losses_valid[-1] < best_model_valid_loss:\n",
    "#     best_model = copy_linear(model)\n",
    "#     best_model = Losses_valid[-1]\n",
    "train_loss.x = list(range(len(Losses))) # add the train steps to graph on x-axis\n",
    "train_loss.y = Losses # add the train losses to graph on y-axis\n",
    "valid_loss.x = list(range(len(Losses_valid)))\n",
    "valid_loss.y = Losses_valid\n",
    "\n",
    "train_acc.x = list(range(len(Accuracy))) # add the train steps to graph on x-axis\n",
    "train_acc.y = Accuracy # add the train losses to graph on y-axis\n",
    "valid_acc.x = list(range(len(Accuracy_valid)))\n",
    "valid_acc.y = Accuracy_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = log_reg(X_test).squeeze()\n",
    "y_test_pred_binary = y_test_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = y_test_pred_binary == Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.linear.weight.data[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = (df['donations'] - df['donations'].mean())/df['donations'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot_max = X[:,0].max().item()\n",
    "x_plot_min = X[:,0].min().item()\n",
    "weight = log_reg.linear.weight.data.squeeze().tolist()\n",
    "bias = log_reg.linear.bias.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_x1s = [x_plot_min, x_plot_max]\n",
    "line_x2s = [(-bias - weight[0]*x_plot_min)/weight[1], (-bias - weight[0]*x_plot_max)/weight[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "true_ind = y_test_pred_binary == True\n",
    "scatter_pred_true = go.Scatter(x=X_test[true_ind,0], y=X_test[true_ind,1], mode='markers', marker=dict(opacity=0.5), name=\"predicted accepted\")\n",
    "scatter_pred_false = go.Scatter(x=X_test[(~true_ind),0], y=X_test[(~true_ind),1], mode='markers', marker=dict(opacity=0.5), name=\"predicted not accepted\")\n",
    "line = go.Scatter(x=line_x1s, y=line_x2s, name='decision boundary')\n",
    "fig.add_traces([scatter_pred_true, scatter_pred_false, line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "correct_ind = correct == True\n",
    "scatter_correct = go.Scatter(x=X_test[correct_ind,0], y=X_test[correct_ind,1], mode='markers', marker=dict(opacity=0.5), name='correct predictions')\n",
    "scatter_incorrect = go.Scatter(x=X_test[~correct_ind,0], y=X_test[~correct_ind,1], mode='markers', marker=dict(opacity=0.5), name='incorrect predictions')\n",
    "# line = go.Scatter(x=X1_line, y=X2_line)\n",
    "fig.add_traces([scatter_correct, scatter_incorrect, line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "accepted = Y_test == True\n",
    "scatter_accepted = go.Scatter(x=X_test[accepted,0], y=X_test[accepted,1], mode='markers', marker=dict(opacity=0.5), name='accepted')\n",
    "scatter_not_accepted = go.Scatter(x=X_test[~accepted,0], y=X_test[~accepted,1], mode='markers', marker=dict(opacity=0.5), name='not accepted')\n",
    "# line = go.Scatter(x=X1_line, y=X2_line)\n",
    "fig.add_traces([scatter_accepted, scatter_not_accepted, line])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
